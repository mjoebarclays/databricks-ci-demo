pipeline {
  agent any
  environment {
    DATABRICKS_HOST  = credentials('DB_HOST_PROD')
    DATABRICKS_TOKEN = credentials('DB_TOKEN_PROD')
  }
  stages {
    stage('Setup CLI') {
      steps {
        sh '''
          python3 -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          pip install databricks-cli jq
          mkdir -p ~/.databricks
          cat > ~/.databricks/config <<EOF
[DEFAULT]
host = $DATABRICKS_HOST
token = $DATABRICKS_TOKEN
EOF
        '''
      }
    }

    stage('Deploy Databricks Job') {
      steps {
        sh '''
          . venv/bin/activate
          JOB_NAME="demo_sql_prod"
          JOB_FILE="jobs/job_sql_warehouse.json"

          JOB_ID=$(databricks jobs list --output JSON | jq -r \
            --arg n "$JOB_NAME" '.jobs[]?|select(.settings.name==$n)|.job_id' | head -1)

          if [ -z "$JOB_ID" ]; then
            echo "Creating new job..."
            databricks jobs create --json-file "$JOB_FILE"
          else
            echo "Updating existing job..."
            databricks jobs reset --job-id "$JOB_ID" --json-file "$JOB_FILE"
          fi
        '''
      }
    }

    stage('Run Databricks Job') {
      steps {
        sh '''
          . venv/bin/activate
          JOB_ID=$(databricks jobs list --output JSON | jq -r \
            --arg n "demo_sql_prod" '.jobs[]?|select(.settings.name==$n)|.job_id' | head -1)
          databricks jobs run-now --job-id "$JOB_ID"
        '''
      }
    }
  }
}
