pipeline {
  agent any
  environment {
    DATABRICKS_HOST  = credentials('DB_HOST_PROD')
    DATABRICKS_TOKEN = credentials('DB_TOKEN_PROD')
  }
  stages {
    stage('Setup CLI') {
  steps {
    sh '''
      python3 -m venv venv
      . venv/bin/activate
      pip install --upgrade pip
      pip install databricks-cli

      # Download jq binary manually (no root needed)
      JQ_BIN=/var/jenkins_home/jq
      if [ ! -f "$JQ_BIN" ]; then
        echo "Downloading jq binary..."
        curl -L -o "$JQ_BIN" https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64
        chmod +x "$JQ_BIN"
      fi
      export PATH=$PATH:/var/jenkins_home

      mkdir -p ~/.databricks
      cat > ~/.databricks/config <<EOF
[DEFAULT]
host = $DATABRICKS_HOST
token = $DATABRICKS_TOKEN
EOF

      databricks jobs configure --version=2.1
    '''
  }
}

    stage('Deploy Databricks Job') {
      steps {
        sh '''
          . venv/bin/activate
          JOB_NAME="demo_sql_prod"
          JOB_FILE="jobs/job_sql_warehouse.json"

          JOB_ID=$(databricks jobs list --output JSON | jq -r \
            --arg n "$JOB_NAME" '.jobs[]?|select(.settings.name==$n)|.job_id' | head -1)

          if [ -z "$JOB_ID" ]; then
            echo "Creating new job..."
            databricks jobs create --json-file "$JOB_FILE"
          else
            echo "Updating existing job..."
            databricks jobs reset --job-id "$JOB_ID" --json-file "$JOB_FILE"
          fi
        '''
      }
    }

    stage('Run Databricks Job') {
      steps {
        sh '''
          . venv/bin/activate
          JOB_ID=$(databricks jobs list --output JSON | jq -r \
            --arg n "demo_sql_prod" '.jobs[]?|select(.settings.name==$n)|.job_id' | head -1)
          databricks jobs run-now --job-id "$JOB_ID"
        '''
      }
    }
  }
}
